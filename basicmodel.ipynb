{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "LR",
   "id": "6b31d5ee291e049"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-14T00:08:52.906678Z",
     "start_time": "2025-05-14T00:08:44.578785Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Image loading and preprocessing\n",
    "# -----------------------------\n",
    "img_data_dir = '../raw'  # Change to your image-dataset folder path\n",
    "\n",
    "image_features = []  # store 1 024-dimensional image features\n",
    "img_labels = []      # store class labels\n",
    "\n",
    "for class_name in os.listdir(img_data_dir):\n",
    "    class_path = os.path.join(img_data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(class_path, filename)).convert('L')\n",
    "                    img = img.resize((32, 32))\n",
    "                    img_array = np.array(img).flatten()\n",
    "                    image_features.append(img_array)\n",
    "                    img_labels.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "image_features = np.array(image_features, dtype=np.float32) / 255.0\n",
    "img_labels = np.array(img_labels)\n",
    "classes = sorted(np.unique(img_labels))\n",
    "num_classes = len(classes)\n",
    "\n",
    "print(f\"Image samples: {image_features.shape[0]}, feature dimension: {image_features.shape[1]}\")\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Build Dataset and DataLoader\n",
    "# -----------------------------\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, features, labels, classes):\n",
    "        self.features = features\n",
    "        self.labels   = labels\n",
    "        self.class2idx = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.class2idx[self.labels[idx]], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_features, img_labels,\n",
    "    test_size=0.1, random_state=42, stratify=img_labels\n",
    ")\n",
    "\n",
    "train_dataset = ImageDataset(X_train, y_train, classes)\n",
    "test_dataset  = ImageDataset(X_test,  y_test,  classes)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader   = DataLoader(test_dataset,  batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}, test samples: {len(test_dataset)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define a simple image-only classifier\n",
    "# -----------------------------\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=1024, hidden_dim=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model  = ImageClassifier(input_dim=1024, hidden_dim=128, num_classes=num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Train the model\n",
    "# -----------------------------\n",
    "criterion   = nn.CrossEntropyLoss()\n",
    "optimizer   = optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_epochs  = 30\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss   = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}/{num_epochs}, Loss: {total_loss/len(train_dataset):.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Evaluate the model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        logits  = model(X_batch)\n",
    "        preds   = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_targets.extend(y_batch.numpy())\n",
    "\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(all_targets, all_preds, target_names=classes))\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d',\n",
    "            xticklabels=classes, yticklabels=classes,\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.title(\"Image Classification Confusion Matrix\")\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像样本数: 3344, 特征维度: 1024\n",
      "类别: [np.str_('Eh-1-1'), np.str_('Eh-1-2'), np.str_('Eh-1-3'), np.str_('Eh-1-4'), np.str_('N-1-1'), np.str_('N-1-2'), np.str_('N-1-3'), np.str_('N-1-4'), np.str_('N-1-5')]\n",
      "训练样本数: 3009, 测试样本数: 335\n",
      "Epoch 5/30, Loss: 1.9013\n",
      "Epoch 10/30, Loss: 1.8415\n",
      "Epoch 15/30, Loss: 1.8008\n",
      "Epoch 20/30, Loss: 1.7637\n",
      "Epoch 25/30, Loss: 1.7325\n",
      "Epoch 30/30, Loss: 1.7060\n",
      "测试集准确率: 0.3522\n",
      "分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Eh-1-1       0.47      0.19      0.27        37\n",
      "      Eh-1-2       0.35      0.31      0.33        61\n",
      "      Eh-1-3       0.29      0.38      0.33        42\n",
      "      Eh-1-4       0.30      0.27      0.28        49\n",
      "       N-1-1       0.37      0.66      0.47        87\n",
      "       N-1-2       0.67      0.27      0.39        22\n",
      "       N-1-3       0.00      0.00      0.00        13\n",
      "       N-1-4       0.00      0.00      0.00         6\n",
      "       N-1-5       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.35       335\n",
      "   macro avg       0.27      0.23      0.23       335\n",
      "weighted avg       0.33      0.35      0.32       335\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 39044 (\\N{CJK UNIFIED IDEOGRAPH-9884}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 31867 (\\N{CJK UNIFIED IDEOGRAPH-7C7B}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21035 (\\N{CJK UNIFIED IDEOGRAPH-522B}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30495 (\\N{CJK UNIFIED IDEOGRAPH-771F}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 23454 (\\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22270 (\\N{CJK UNIFIED IDEOGRAPH-56FE}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20687 (\\N{CJK UNIFIED IDEOGRAPH-50CF}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 28151 (\\N{CJK UNIFIED IDEOGRAPH-6DF7}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 28102 (\\N{CJK UNIFIED IDEOGRAPH-6DC6}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30697 (\\N{CJK UNIFIED IDEOGRAPH-77E9}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 38453 (\\N{CJK UNIFIED IDEOGRAPH-9635}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T05:16:10.156988Z",
     "start_time": "2025-05-15T05:16:10.141070Z"
    }
   },
   "cell_type": "code",
   "source": "GAT",
   "id": "3f9c0b01744a7018",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "# 1. Data loading and preprocessing\n",
    "# Replace data_dir with the path to your extracted dataset folder\n",
    "data_dir = '../raw'\n",
    "\n",
    "X = []  # store image data\n",
    "y = []  # store class labels\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')          # convert to grayscale\n",
    "                    img = img.resize((32, 32))      # resize to 32 × 32\n",
    "                    img_array = np.array(img).flatten()  # flatten to a 1024-dim vector\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X, dtype='float32') / 255.0  # normalize\n",
    "y = np.array(y)\n",
    "print(\"Total images loaded:\", X.shape[0])\n",
    "print(\"Features per sample:\", X.shape[1])\n",
    "print(\"Original class labels:\", np.unique(y))\n",
    "\n",
    "# 2. Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# 3. Build graph structure (KNN)\n",
    "k = 10  # number of neighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "edge_index = []\n",
    "num_nodes = X.shape[0]\n",
    "for i in range(num_nodes):\n",
    "    for j in indices[i]:\n",
    "        if i != j:                       # exclude self-loops (add if needed)\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])    # add reverse edge for an undirected graph\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# 4. Build PyG Data object\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# Stratified 80 %/20 % train/test node split\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx]   = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "print(\"Training nodes:\", int(train_mask.sum()))\n",
    "print(\"Test nodes    :\", int(test_mask.sum()))\n",
    "\n",
    "# 5. Define the GAT model\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels,\n",
    "                 out_channels, heads=8, dropout=0.6):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels,\n",
    "                            heads=heads, dropout=dropout)\n",
    "        # First layer output dim is hidden_channels * heads\n",
    "        self.gat2 = GATConv(hidden_channels * heads, out_channels,\n",
    "                            heads=1, concat=False, dropout=dropout)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAT(in_channels=X.shape[1],\n",
    "            hidden_channels=64,\n",
    "            out_channels=num_classes).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 6. Train the GAT model\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 7. Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    print(f\"Test accuracy: {acc:.4f}\")\n"
   ],
   "id": "735999a793ee20a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "GCN",
   "id": "6b1c56dda07a36dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Image loading and preprocessing\n",
    "# Replace data_dir with the path to your extracted dataset\n",
    "data_dir = '../raw'\n",
    "\n",
    "X = []  # store image data\n",
    "y = []  # store class labels\n",
    "\n",
    "# Traverse the dataset folder; each sub-folder represents a class\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')            # convert to grayscale\n",
    "                    img = img.resize((32, 32))        # resize to 32 × 32\n",
    "                    img_array = np.array(img).flatten()  # flatten to 1 024-dim vector\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X, dtype='float32') / 255.0  # normalize\n",
    "y = np.array(y)\n",
    "print(\"Total images loaded:\", X.shape[0])\n",
    "print(\"Feature dimension per sample:\", X.shape[1])\n",
    "print(\"Original class labels:\", np.unique(y))\n",
    "\n",
    "# 2. Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# 3. Build graph structure with KNN\n",
    "k = 10  # number of neighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "_, indices = nbrs.kneighbors(X)\n",
    "\n",
    "edge_index = []\n",
    "num_nodes = X.shape[0]\n",
    "for i in range(num_nodes):\n",
    "    for j in indices[i]:\n",
    "        if i != j:                       # exclude self-loops (add if needed)\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])    # add reverse edge to make an undirected graph\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# 4. Build PyG Data object\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# Stratified 80 %/20 % train/test node split\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx]   = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "print(\"Training nodes:\", int(train_mask.sum()))\n",
    "print(\"Test nodes    :\", int(test_mask.sum()))\n",
    "\n",
    "# 5. Define the GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(in_channels=X.shape[1],\n",
    "            hidden_channels=64,\n",
    "            out_channels=num_classes).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 6. Train the GCN model\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out  = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 7. Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out  = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    print(f\"Test accuracy: {acc:.4f}\")\n"
   ],
   "id": "94b63fa4bdf1344b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ResNet",
   "id": "4c4e50cd9d9eb269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. Image loading and preprocessing\n",
    "data_dir = '../raw'  # Change to your dataset path; each subfolder corresponds to a class\n",
    "image_size = (32, 32)  # Image size (H, W)\n",
    "\n",
    "X = []  # store image data\n",
    "y = []  # store class labels\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')               # convert to grayscale\n",
    "                    img = img.resize(image_size)         # resize to 32×32\n",
    "                    img_array = np.array(img, dtype=np.float32) / 255.0  # normalize to [0,1]\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X)  # shape: (N, H, W)\n",
    "y = np.array(y)\n",
    "print(\"Total images loaded:\", X.shape[0])\n",
    "print(\"Image size:\", X.shape[1:], \"Original class labels:\", np.unique(y))\n",
    "\n",
    "# 2. Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# 3. Build Dataset and DataLoader\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images  # shape: (N, H, W)\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # convert to [C, H, W]; grayscale so C = 1\n",
    "        image = self.images[idx]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "train_images, test_images = X[train_idx], X[test_idx]\n",
    "train_labels, test_labels = y_encoded[train_idx], y_encoded[test_idx]\n",
    "\n",
    "train_dataset = ImageDataset(train_images, train_labels)\n",
    "test_dataset  = ImageDataset(test_images,  test_labels)\n",
    "\n",
    "batch_size   = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 4. Define the ResNet model\n",
    "# 4.1 BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes, eps=1e-5)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes, eps=1e-5)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes, eps=1e-5)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# 4.2 ResNet backbone\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10, in_channels=1):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        # For small images, use 3×3 conv with stride 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1  = nn.BatchNorm2d(64, eps=1e-5)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # layer1: no downsampling; layer2–4: downsample\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc      = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride):\n",
    "        layers = [block(self.in_planes, planes, stride)]\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        x = self.layer1(x); x = self.layer2(x)\n",
    "        x = self.layer3(x); x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def resnet18(num_classes, in_channels=1):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes, in_channels=in_channels)\n",
    "\n",
    "# Instantiate the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = resnet18(num_classes=num_classes, in_channels=1).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 5. Training and evaluation\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total   = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs        = model(images)\n",
    "        _, predicted   = torch.max(outputs, 1)\n",
    "        total  += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ],
   "id": "4315e4801efe182d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "heterognn+resnet",
   "id": "1748c5e1f9756729"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Image loading and preprocessing\n",
    "# -----------------------------\n",
    "data_dir   = '../raw'          # Path to your image-dataset folder; each sub-folder is a class\n",
    "image_size = (32, 32)          # Image size (H, W)\n",
    "\n",
    "images = []  # store image data (H, W)\n",
    "labels = []  # store class labels\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')                 # grayscale\n",
    "                    img = img.resize(image_size)\n",
    "                    img_array = np.array(img, dtype=np.float32) / 255.0  # normalize to [0, 1]\n",
    "                    images.append(img_array)\n",
    "                    labels.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "images = np.array(images)      # (N, H, W)\n",
    "labels = np.array(labels)\n",
    "print(\"Total images loaded:\", images.shape[0])\n",
    "print(\"Image size:\", images.shape[1:], \"Original class labels:\", np.unique(labels))\n",
    "\n",
    "# Label encoding\n",
    "le         = LabelEncoder()\n",
    "y_encoded  = le.fit_transform(labels)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# Dataset definition\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images   # (N, H, W)\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # convert to [C, H, W]; grayscale so C = 1\n",
    "        img   = np.expand_dims(self.images[idx], axis=0)\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Train / test split\n",
    "indices = np.arange(len(images))\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "train_images, test_images   = images[train_idx], images[test_idx]\n",
    "train_labels, test_labels   = y_encoded[train_idx], y_encoded[test_idx]\n",
    "\n",
    "train_dataset = ImageDataset(train_images, train_labels)\n",
    "test_dataset  = ImageDataset(test_images,  test_labels)\n",
    "\n",
    "batch_size   = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Graph-data encoding (HeteroGNN)\n",
    "# -----------------------------\n",
    "# Example: suppose your heterogeneous-graph data are stored in a dict;\n",
    "# each node type has its own feature matrix.  Adjust to match your data.\n",
    "graph_data = {\n",
    "    'type1': torch.randn(10, 16),   # 10 nodes, 16-dim features\n",
    "    'type2': torch.randn(15, 16)    # 15 nodes, 16-dim features\n",
    "}\n",
    "\n",
    "class HeteroGNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple heterogeneous-graph encoder.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    in_feats : input feature dimension (assumed identical across types)\n",
    "    hidden_feats : hidden dimension\n",
    "    out_feats : dimension of the final graph embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super().__init__()\n",
    "        # For simplicity every node uses the same two-layer MLP\n",
    "        self.fc1 = nn.Linear(in_feats,  hidden_feats)\n",
    "        self.fc2 = nn.Linear(hidden_feats, out_feats)\n",
    "        \n",
    "    def forward(self, graph_dict):\n",
    "        encodings = []\n",
    "        for _, feats in graph_dict.items():          # feats: (N_i, in_feats)\n",
    "            h = F.relu(self.fc1(feats))\n",
    "            h = self.fc2(h)                          # (N_i, out_feats)\n",
    "            encodings.append(h)\n",
    "        all_feats = torch.cat(encodings, dim=0)      # (Σ nodes, out_feats)\n",
    "        return all_feats.mean(dim=0)                 # (out_feats,)\n",
    "\n",
    "heterognn_encoder = HeteroGNNEncoder(in_feats=16, hidden_feats=32, out_feats=768)\n",
    "heterognn_encoder.eval()\n",
    "with torch.no_grad():\n",
    "    graph_hidden_state = heterognn_encoder(graph_data)  # (768,)\n",
    "print(\"Graph-embedding vector shape:\", graph_hidden_state.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. ResNet with graph-plugin fusion\n",
    "# -----------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, 3, stride, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, 3, 1, 1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(planes)\n",
    "        self.down  = None\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.down = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.down is not None:\n",
    "            identity = self.down(x)\n",
    "        out = self.relu(out + identity)\n",
    "        return out\n",
    "\n",
    "class ResNetPlugin(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes, in_channels=1, graph_dim=768):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, 3, 1, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(64)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], 1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], 2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], 2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], 2)\n",
    "        \n",
    "        self.avgpool   = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_plugin = nn.Linear(512 + graph_dim, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride):\n",
    "        layers = [block(self.in_planes, planes, stride)]\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x, graph_vector):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x); x = self.layer2(x)\n",
    "        x = self.layer3(x); x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x).flatten(1)            # (B, 512)\n",
    "        B = x.size(0)\n",
    "        graph_expanded = graph_vector.unsqueeze(0).expand(B, -1)  # (B, graph_dim)\n",
    "        fused = torch.cat([x, graph_expanded], dim=1)\n",
    "        return self.fc_plugin(fused)\n",
    "\n",
    "def resnet18_plugin(num_classes, in_channels=1, graph_dim=768):\n",
    "    return ResNetPlugin(BasicBlock, [2, 2, 2, 2],\n",
    "                        num_classes=num_classes,\n",
    "                        in_channels=in_channels,\n",
    "                        graph_dim=graph_dim)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Training and evaluation\n",
    "# -----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = resnet18_plugin(num_classes=num_classes, in_channels=1, graph_dim=768).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "graph_hidden_state = graph_hidden_state.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, lbls in train_loader:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs, graph_hidden_state)\n",
    "        loss    = criterion(outputs, lbls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} — Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Evaluation and confusion matrix\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, lbls in test_loader:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        outputs    = model(imgs, graph_hidden_state)\n",
    "        _, preds   = torch.max(outputs, 1)\n",
    "        total  += lbls.size(0)\n",
    "        correct += (preds == lbls).sum().item()\n",
    "        y_true.extend(lbls.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "ticks = np.arange(num_classes)\n",
    "plt.xticks(ticks, le.classes_, rotation=45)\n",
    "plt.yticks(ticks, le.classes_)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "c60515f2f29cad03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
