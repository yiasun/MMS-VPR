{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-15T08:29:00.512625Z",
     "start_time": "2025-05-15T08:22:09.388164Z"
    }
   },
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HGTConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load & preprocess images + build KNN graph\n",
    "# -------------------------------\n",
    "data_dir = '../all'  # Change to your image dataset path\n",
    "X, y = [], []\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for fname in os.listdir(class_path):\n",
    "            if fname.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp')):\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(class_path, fname)).convert('L')\n",
    "                    img = img.resize((32, 32))\n",
    "                    arr = np.array(img).flatten()\n",
    "                    X.append(arr)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {fname}: {e}\")\n",
    "\n",
    "X = np.array(X, dtype=np.float32) / 255.0\n",
    "y = np.array(y)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_nodes, feat_dim = X.shape\n",
    "num_classes = len(le.classes_)\n",
    "print(f\"Number of nodes: {num_nodes}, Feature dimension: {feat_dim}, Number of classes: {num_classes}\")\n",
    "\n",
    "# Build KNN graph\n",
    "k = 10\n",
    "nbrs = NearestNeighbors(n_neighbors=k).fit(X)\n",
    "_, idx = nbrs.kneighbors(X)\n",
    "edges = []\n",
    "for i in range(num_nodes):\n",
    "    for j in idx[i]:\n",
    "        if i != j:\n",
    "            edges.append([i, j])\n",
    "            edges.append([j, i])\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Split train/test\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Text prior: extract [CLS] vector with BERT\n",
    "# -------------------------------\n",
    "text_path = 'Final Dataset-Texts.xlsx'  # Change path as needed\n",
    "df_text = pd.read_excel(text_path)\n",
    "first_text = df_text['List of Store Names'].iloc[0]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-chinese\").eval()\n",
    "with torch.no_grad():\n",
    "    tok = tokenizer(first_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    out = bert_model(**tok)\n",
    "    text_vec = out.last_hidden_state[:, 0, :].squeeze(0)  # (768,)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Build HeteroData object\n",
    "# -------------------------------\n",
    "data = HeteroData()\n",
    "# Image nodes\n",
    "data['image'].x = torch.tensor(X)\n",
    "data['image'].y = torch.tensor(y_encoded)\n",
    "data['image'].train_mask = train_mask\n",
    "data['image'].test_mask = test_mask\n",
    "data['image', 'to', 'image'].edge_index = edge_index\n",
    "\n",
    "# Text node (single node)\n",
    "data['text'].x = text_vec.unsqueeze(0)  # (1, 768)\n",
    "\n",
    "# Connect text ↔ image\n",
    "src = torch.zeros(num_nodes, dtype=torch.long)          # text node index = 0\n",
    "dst = torch.arange(num_nodes, dtype=torch.long)         # image nodes 0..num_nodes-1\n",
    "data['text', 'to', 'image'].edge_index = torch.vstack([src, dst])\n",
    "data['image', 'to', 'text'].edge_index = torch.vstack([dst, src])\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Define HeteroGNN model\n",
    "# -------------------------------\n",
    "class HeteroGNN(nn.Module):\n",
    "    def __init__(self, img_dim, txt_dim, hidden, out_dim):\n",
    "        super().__init__()\n",
    "        # Project different node types to a common hidden size\n",
    "        self.lin_img = nn.Linear(img_dim, hidden)\n",
    "        self.lin_txt = nn.Linear(txt_dim, hidden)\n",
    "        # Meta-information of the heterogeneous graph\n",
    "        self.metadata = data.metadata()\n",
    "        # Two HGTConv layers\n",
    "        self.conv1 = HGTConv(hidden, hidden, self.metadata, heads=2)\n",
    "        self.conv2 = HGTConv(hidden, hidden, self.metadata, heads=2)\n",
    "        # Final classifier for image nodes\n",
    "        self.cls = nn.Linear(hidden, out_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict = {\n",
    "            'image': F.relu(self.lin_img(data['image'].x)),\n",
    "            'text':  F.relu(self.lin_txt(data['text'].x))\n",
    "        }\n",
    "        # Message passing layer 1\n",
    "        x_dict = self.conv1(x_dict, data.edge_index_dict)\n",
    "        x_dict = {k: F.relu(v) for k, v in x_dict.items()}\n",
    "        # Message passing layer 2\n",
    "        x_dict = self.conv2(x_dict, data.edge_index_dict)\n",
    "        # Predict only for image nodes\n",
    "        out = self.cls(x_dict['image'])\n",
    "        return out\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Training and evaluation\n",
    "# -------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HeteroGNN(img_dim=feat_dim, txt_dim=text_vec.size(0),\n",
    "                  hidden=64, out_dim=num_classes).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(data)\n",
    "    loss = criterion(logits[data['image'].train_mask],\n",
    "                     data['image'].y[data['image'].train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"[HeteroGNN] Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(data)\n",
    "    pred = logits.argmax(dim=1).cpu().numpy()\n",
    "    y_true = data['image'].y[data['image'].test_mask].cpu().numpy()\n",
    "    y_pred = pred[data['image'].test_mask.cpu().numpy()]\n",
    "\n",
    "    print(\"HeteroGNN Test Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='macro'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='macro'))\n",
    "    print(\"F1-score :\", f1_score(y_true, y_pred, average='macro'))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点数: 78575, 特征维度: 1024, 类别数: 207\n",
      "[HeteroGNN] Epoch 000, Loss: 5.3375\n",
      "[HeteroGNN] Epoch 020, Loss: 5.0637\n",
      "[HeteroGNN] Epoch 040, Loss: 4.9287\n",
      "[HeteroGNN] Epoch 060, Loss: 4.7973\n",
      "[HeteroGNN] Epoch 080, Loss: 4.7675\n",
      "[HeteroGNN] Epoch 100, Loss: 4.6830\n",
      "[HeteroGNN] Epoch 120, Loss: 4.6063\n",
      "[HeteroGNN] Epoch 140, Loss: 4.5645\n",
      "[HeteroGNN] Epoch 160, Loss: 4.5447\n",
      "[HeteroGNN] Epoch 180, Loss: 4.4687\n",
      "HeteroGNN Test Accuracy: 0.07311485841552656\n",
      "Precision: 0.016192157111485465\n",
      "Recall   : 0.027383932590461093\n",
      "F1-score : 0.015102539694945778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "17bf2c937f20d72b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
