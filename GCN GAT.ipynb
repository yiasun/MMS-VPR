{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-05T19:09:22.541494Z",
     "start_time": "2025-05-05T19:06:49.505109Z"
    }
   },
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load & preprocess images and build the graph\n",
    "# -------------------------------\n",
    "data_dir = '../all'  # Change to your image-dataset folder path\n",
    "\n",
    "X = []  # store image data (each image flattened to a 1024-dimensional vector)\n",
    "y = []  # store class labels\n",
    "\n",
    "# Traverse the dataset folder; each sub-folder represents a class\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')          # convert to grayscale\n",
    "                    img = img.resize((32, 32))      # resize to 32×32\n",
    "                    img_array = np.array(img).flatten()  # flatten to 1024-dim vector\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X, dtype='float32') / 255.0  # normalize\n",
    "y = np.array(y)\n",
    "print(\"Total images read:\", X.shape[0])\n",
    "print(\"Features per sample:\", X.shape[1])\n",
    "print(\"Original class labels:\", np.unique(y))\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# Build a KNN graph\n",
    "k = 10\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "_, indices = nbrs.kneighbors(X)\n",
    "edge_index = []\n",
    "num_nodes = X.shape[0]\n",
    "for i in range(num_nodes):\n",
    "    for j in indices[i]:\n",
    "        if i != j:  # exclude self-loops\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])  # bidirectional edges\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Construct the PyG Data object\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# Split nodes into train/test sets\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx]   = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "print(\"Number of training nodes:\", int(train_mask.sum()))\n",
    "print(\"Number of test nodes:\", int(test_mask.sum()))\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Text prior: read Excel and obtain the [CLS] vector via BERT\n",
    "# -------------------------------\n",
    "text_data_path = 'Final Dataset-Texts.xlsx'  # Change to your Excel file path\n",
    "df_text = pd.read_excel(text_data_path)\n",
    "# Use the first row in “List of Store Names” as plugin information (example only)\n",
    "first_text = df_text['List of Store Names'].iloc[0]\n",
    "print(\"First row text:\", first_text)\n",
    "\n",
    "# Use a pre-trained BERT model (bert-base-chinese if the text is Chinese)\n",
    "tokenizer   = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model  = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs  = tokenizer(first_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = bert_model(**inputs)\n",
    "    # Get the [CLS] token hidden state, shape (1, 768)\n",
    "    text_hidden_state = outputs.last_hidden_state[:, 0, :].squeeze(0)  # (768,)\n",
    "print(\"Text hidden state shape:\", text_hidden_state.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Define a GCN model with text plugin\n",
    "# -------------------------------\n",
    "class GCNPlugin(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, text_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # After fusion the dimension is hidden_channels + text_dim\n",
    "        self.classifier = nn.Linear(hidden_channels + text_dim, out_channels)\n",
    "    \n",
    "    def forward(self, data, text_vector):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x shape: (num_nodes, hidden_channels)\n",
    "        num_nodes = x.size(0)\n",
    "        # Expand text_vector (text_dim,) to (num_nodes, text_dim)\n",
    "        text_expanded = text_vector.unsqueeze(0).expand(num_nodes, -1)\n",
    "        # Fuse: concatenate image embeddings and text plugin\n",
    "        fused = torch.cat([x, text_expanded], dim=1)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCNPlugin(in_channels=X.shape[1],\n",
    "                  hidden_channels=64,\n",
    "                  out_channels=num_classes,\n",
    "                  text_dim=768).to(device)\n",
    "data = data.to(device)\n",
    "text_hidden_state = text_hidden_state.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Train the model\n",
    "# -------------------------------\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out  = model(data, text_hidden_state)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Evaluate the model\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out  = model(data, text_hidden_state)\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "    # Only consider test nodes\n",
    "    y_true = data.y[data.test_mask].cpu().numpy()\n",
    "    y_pred = pred[data.test_mask].cpu().numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    rec  = recall_score(y_true, y_pred, average='macro')\n",
    "    f1   = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Test Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision     : {prec:.4f}\")\n",
    "    print(f\"Recall        : {rec:.4f}\")\n",
    "    print(f\"F1-score      : {f1:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总计读取图像数： 78575\n",
      "每个样本的特征数： 1024\n",
      "原始类别标签： ['Eh-1-1' 'Eh-1-2' 'Eh-1-3' 'Eh-1-4' 'Eh-10-1' 'Eh-10-2' 'Eh-10-3'\n",
      " 'Eh-10-4' 'Eh-10-5' 'Eh-10-6' 'Eh-10-7' 'Eh-10-8' 'Eh-10-9' 'Eh-11-1'\n",
      " 'Eh-11-2' 'Eh-11-3' 'Eh-11-4' 'Eh-12-1' 'Eh-12-2' 'Eh-12-3' 'Eh-12-4'\n",
      " 'Eh-12-5' 'Eh-12-6' 'Eh-12-7' 'Eh-12-8' 'Eh-12-9' 'Eh-14-1' 'Eh-14-10'\n",
      " 'Eh-14-2' 'Eh-14-3' 'Eh-14-4' 'Eh-14-5' 'Eh-14-6' 'Eh-14-7' 'Eh-14-8'\n",
      " 'Eh-14-9' 'Eh-2-1' 'Eh-2-2' 'Eh-2-3' 'Eh-3-1' 'Eh-3-2' 'Eh-3-3' 'Eh-4-1'\n",
      " 'Eh-5-1' 'Eh-5-2' 'Eh-6-1' 'Eh-6-2' 'Eh-7-1' 'Eh-7-2' 'Eh-7-3' 'Eh-8-1'\n",
      " 'Eh-8-2' 'Eh-8-3' 'Eh-8-4' 'Eh-8-5' 'Eh-8-6' 'Eh-8-7' 'Eh-9-1' 'Eh-9-2'\n",
      " 'Eh-9-3' 'Eh-9-4' 'Ev-1-1' 'Ev-1-2' 'Ev-1-3' 'Ev-1-4' 'Ev-1-5' 'Ev-1-6'\n",
      " 'Ev-1-7' 'Ev-1-8' 'Ev-10-1' 'Ev-10-10' 'Ev-10-2' 'Ev-10-3' 'Ev-10-4'\n",
      " 'Ev-10-5' 'Ev-10-6' 'Ev-10-7' 'Ev-10-8' 'Ev-10-9' 'Ev-11-1' 'Ev-11-2'\n",
      " 'Ev-11-3' 'Ev-12-1' 'Ev-12-2' 'Ev-13-1' 'Ev-2-1' 'Ev-2-2' 'Ev-2-3'\n",
      " 'Ev-2-4' 'Ev-2-5' 'Ev-2-6' 'Ev-2-7' 'Ev-2-8' 'Ev-2-9' 'Ev-3-1' 'Ev-3-2'\n",
      " 'Ev-3-3' 'Ev-3-4' 'Ev-4-1' 'Ev-5-1' 'Ev-5-2' 'Ev-5-3' 'Ev-6-1' 'Ev-7-1'\n",
      " 'Ev-7-2' 'Ev-7-3' 'Ev-7-4' 'Ev-7-5' 'Ev-7-6' 'Ev-8-1' 'Ev-8-2' 'Ev-8-3'\n",
      " 'Ev-8-4' 'Ev-8-5' 'Ev-9-1' 'Ev-9-10' 'Ev-9-11' 'Ev-9-2' 'Ev-9-3' 'Ev-9-4'\n",
      " 'Ev-9-5' 'Ev-9-6' 'Ev-9-7' 'Ev-9-8' 'Ev-9-9' 'N-1-1' 'N-1-2' 'N-1-3'\n",
      " 'N-1-4' 'N-1-5' 'N-10-1' 'N-10-10' 'N-10-2' 'N-10-3' 'N-10-4' 'N-10-5'\n",
      " 'N-10-6' 'N-10-7' 'N-10-8' 'N-10-9' 'N-11-1' 'N-11-2' 'N-11-3' 'N-11-4'\n",
      " 'N-11-5' 'N-12-1' 'N-12-10' 'N-12-2' 'N-12-3' 'N-12-4' 'N-12-5' 'N-12-6'\n",
      " 'N-12-7' 'N-12-8' 'N-12-9' 'N-13-1' 'N-13-2' 'N-14-1' 'N-14-10' 'N-14-11'\n",
      " 'N-14-2' 'N-14-3' 'N-14-4' 'N-14-5' 'N-14-6' 'N-14-7' 'N-14-8' 'N-14-9'\n",
      " 'N-2-1' 'N-2-2' 'N-2-3' 'N-2-4' 'N-2-5' 'N-3-1' 'N-3-2' 'N-3-3' 'N-3-4'\n",
      " 'N-3-5' 'N-4-1' 'N-4-2' 'N-5-1' 'N-5-2' 'N-5-3' 'N-5-4' 'N-6-1' 'N-6-2'\n",
      " 'N-6-3' 'N-6-4' 'N-7-1' 'N-7-2' 'N-7-3' 'N-7-4' 'N-7-5' 'N-8-1' 'N-8-2'\n",
      " 'N-8-3' 'N-8-4' 'N-8-5' 'N-8-6' 'N-8-7' 'N-8-8' 'N-9-1' 'N-9-2' 'N-9-3'\n",
      " 'N-9-4' 'N-9-5' 'S-1']\n",
      "编码后的类别数： 207\n",
      "训练节点数： 62860\n",
      "测试节点数： 15715\n",
      "第一行文本： WM HOUSE, MC HOUSE 展览馆, 交通银行, 良品铺子\n",
      "文本 hidden state shape: torch.Size([768])\n",
      "Epoch 000, Loss: 5.3948\n",
      "Epoch 020, Loss: 5.0590\n",
      "Epoch 040, Loss: 4.9418\n",
      "Epoch 060, Loss: 4.8720\n",
      "Epoch 080, Loss: 4.8117\n",
      "Epoch 100, Loss: 4.7404\n",
      "Epoch 120, Loss: 4.6812\n",
      "Epoch 140, Loss: 4.6396\n",
      "Epoch 160, Loss: 4.6081\n",
      "Epoch 180, Loss: 4.5799\n",
      "Test Accuracy : 0.0741\n",
      "Precision     : 0.0380\n",
      "Recall        : 0.0334\n",
      "F1-score      : 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GAT",
   "id": "55aa06fd498c514"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T19:20:38.611679Z",
     "start_time": "2025-05-05T19:15:18.101373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Image loading, preprocessing, and graph construction\n",
    "# ---------------------------\n",
    "data_dir = '../all'  # Change to your image-dataset folder path\n",
    "\n",
    "X = []  # store image data (each image flattened to a 1024-dimensional vector)\n",
    "y = []  # store class labels\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')          # convert to grayscale\n",
    "                    img = img.resize((32, 32))      # resize to 32×32\n",
    "                    img_array = np.array(img).flatten()  # flatten to 1024-dim vector\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X, dtype='float32') / 255.0  # normalize to [0, 1]\n",
    "y = np.array(y)\n",
    "print(\"Total images loaded:\", X.shape[0])\n",
    "print(\"Features per sample:\", X.shape[1])\n",
    "print(\"Original class labels:\", np.unique(y))\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# Build a KNN graph\n",
    "k = 10\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "_, indices = nbrs.kneighbors(X)\n",
    "\n",
    "edge_index = []\n",
    "num_nodes = X.shape[0]\n",
    "for i in range(num_nodes):\n",
    "    for j in indices[i]:\n",
    "        if i != j:                         # exclude self-loops\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])      # bidirectional edges\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Construct a PyG Data object\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# Stratified train/test node split\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx]   = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "print(\"Training nodes:\", int(train_mask.sum()))\n",
    "print(\"Test nodes    :\", int(test_mask.sum()))\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Text prior: load Excel and obtain the [CLS] vector via BERT\n",
    "# ---------------------------\n",
    "text_data_path = 'Final Dataset-Texts.xlsx'  # Change to your Excel file path\n",
    "df_text = pd.read_excel(text_data_path)\n",
    "# Take the first row of “List of Store Names” as plugin information (example only)\n",
    "first_text = df_text['List of Store Names'].iloc[0]\n",
    "print(\"First row text:\", first_text)\n",
    "\n",
    "# Use a pre-trained BERT model (bert-base-chinese if the text is Chinese)\n",
    "tokenizer  = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs  = tokenizer(first_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = bert_model(**inputs)\n",
    "    # Extract the [CLS] token hidden state, shape (1, 768)\n",
    "    text_hidden_state = outputs.last_hidden_state[:, 0, :].squeeze(0)  # (768,)\n",
    "print(\"Text hidden state shape:\", text_hidden_state.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Define a plugin-based multimodal GAT model\n",
    "# ---------------------------\n",
    "class GATPlugin(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes, text_dim,\n",
    "                 heads=8, dropout=0.6):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels,\n",
    "                            heads=heads, dropout=dropout)\n",
    "        # First layer output dimension = hidden_channels * heads\n",
    "        self.gat2 = GATConv(hidden_channels * heads, hidden_channels,\n",
    "                            heads=1, concat=False, dropout=dropout)\n",
    "        # Fusion dimension: hidden_channels + text_dim\n",
    "        self.classifier = nn.Linear(hidden_channels + text_dim, num_classes)\n",
    "    \n",
    "    def forward(self, data, text_vector):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)            # (num_nodes, hidden_channels)\n",
    "        num_nodes = x.size(0)\n",
    "        text_expanded = text_vector.unsqueeze(0).expand(num_nodes, -1)\n",
    "        fused = torch.cat([x, text_expanded], dim=1)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GATPlugin(in_channels=X.shape[1],\n",
    "                  hidden_channels=64,\n",
    "                  num_classes=num_classes,\n",
    "                  text_dim=768).to(device)\n",
    "data = data.to(device)\n",
    "text_hidden_state = text_hidden_state.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Train the model\n",
    "# ---------------------------\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out  = model(data, text_hidden_state)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Evaluate the model\n",
    "# ---------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out  = model(data, text_hidden_state)\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "    # Only consider test nodes\n",
    "    y_true = data.y[data.test_mask].cpu().numpy()\n",
    "    y_pred = pred[data.test_mask].cpu().numpy()\n",
    "\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    rec  = recall_score(y_true, y_pred, average='macro')\n",
    "    f1   = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(f\"Test Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision     : {prec:.4f}\")\n",
    "    print(f\"Recall        : {rec:.4f}\")\n",
    "    print(f\"F1-score      : {f1:.4f}\")\n"
   ],
   "id": "d0d3606ac803445e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总计读取图像数： 78575\n",
      "每个样本的特征数： 1024\n",
      "原始类别标签： ['Eh-1-1' 'Eh-1-2' 'Eh-1-3' 'Eh-1-4' 'Eh-10-1' 'Eh-10-2' 'Eh-10-3'\n",
      " 'Eh-10-4' 'Eh-10-5' 'Eh-10-6' 'Eh-10-7' 'Eh-10-8' 'Eh-10-9' 'Eh-11-1'\n",
      " 'Eh-11-2' 'Eh-11-3' 'Eh-11-4' 'Eh-12-1' 'Eh-12-2' 'Eh-12-3' 'Eh-12-4'\n",
      " 'Eh-12-5' 'Eh-12-6' 'Eh-12-7' 'Eh-12-8' 'Eh-12-9' 'Eh-14-1' 'Eh-14-10'\n",
      " 'Eh-14-2' 'Eh-14-3' 'Eh-14-4' 'Eh-14-5' 'Eh-14-6' 'Eh-14-7' 'Eh-14-8'\n",
      " 'Eh-14-9' 'Eh-2-1' 'Eh-2-2' 'Eh-2-3' 'Eh-3-1' 'Eh-3-2' 'Eh-3-3' 'Eh-4-1'\n",
      " 'Eh-5-1' 'Eh-5-2' 'Eh-6-1' 'Eh-6-2' 'Eh-7-1' 'Eh-7-2' 'Eh-7-3' 'Eh-8-1'\n",
      " 'Eh-8-2' 'Eh-8-3' 'Eh-8-4' 'Eh-8-5' 'Eh-8-6' 'Eh-8-7' 'Eh-9-1' 'Eh-9-2'\n",
      " 'Eh-9-3' 'Eh-9-4' 'Ev-1-1' 'Ev-1-2' 'Ev-1-3' 'Ev-1-4' 'Ev-1-5' 'Ev-1-6'\n",
      " 'Ev-1-7' 'Ev-1-8' 'Ev-10-1' 'Ev-10-10' 'Ev-10-2' 'Ev-10-3' 'Ev-10-4'\n",
      " 'Ev-10-5' 'Ev-10-6' 'Ev-10-7' 'Ev-10-8' 'Ev-10-9' 'Ev-11-1' 'Ev-11-2'\n",
      " 'Ev-11-3' 'Ev-12-1' 'Ev-12-2' 'Ev-13-1' 'Ev-2-1' 'Ev-2-2' 'Ev-2-3'\n",
      " 'Ev-2-4' 'Ev-2-5' 'Ev-2-6' 'Ev-2-7' 'Ev-2-8' 'Ev-2-9' 'Ev-3-1' 'Ev-3-2'\n",
      " 'Ev-3-3' 'Ev-3-4' 'Ev-4-1' 'Ev-5-1' 'Ev-5-2' 'Ev-5-3' 'Ev-6-1' 'Ev-7-1'\n",
      " 'Ev-7-2' 'Ev-7-3' 'Ev-7-4' 'Ev-7-5' 'Ev-7-6' 'Ev-8-1' 'Ev-8-2' 'Ev-8-3'\n",
      " 'Ev-8-4' 'Ev-8-5' 'Ev-9-1' 'Ev-9-10' 'Ev-9-11' 'Ev-9-2' 'Ev-9-3' 'Ev-9-4'\n",
      " 'Ev-9-5' 'Ev-9-6' 'Ev-9-7' 'Ev-9-8' 'Ev-9-9' 'N-1-1' 'N-1-2' 'N-1-3'\n",
      " 'N-1-4' 'N-1-5' 'N-10-1' 'N-10-10' 'N-10-2' 'N-10-3' 'N-10-4' 'N-10-5'\n",
      " 'N-10-6' 'N-10-7' 'N-10-8' 'N-10-9' 'N-11-1' 'N-11-2' 'N-11-3' 'N-11-4'\n",
      " 'N-11-5' 'N-12-1' 'N-12-10' 'N-12-2' 'N-12-3' 'N-12-4' 'N-12-5' 'N-12-6'\n",
      " 'N-12-7' 'N-12-8' 'N-12-9' 'N-13-1' 'N-13-2' 'N-14-1' 'N-14-10' 'N-14-11'\n",
      " 'N-14-2' 'N-14-3' 'N-14-4' 'N-14-5' 'N-14-6' 'N-14-7' 'N-14-8' 'N-14-9'\n",
      " 'N-2-1' 'N-2-2' 'N-2-3' 'N-2-4' 'N-2-5' 'N-3-1' 'N-3-2' 'N-3-3' 'N-3-4'\n",
      " 'N-3-5' 'N-4-1' 'N-4-2' 'N-5-1' 'N-5-2' 'N-5-3' 'N-5-4' 'N-6-1' 'N-6-2'\n",
      " 'N-6-3' 'N-6-4' 'N-7-1' 'N-7-2' 'N-7-3' 'N-7-4' 'N-7-5' 'N-8-1' 'N-8-2'\n",
      " 'N-8-3' 'N-8-4' 'N-8-5' 'N-8-6' 'N-8-7' 'N-8-8' 'N-9-1' 'N-9-2' 'N-9-3'\n",
      " 'N-9-4' 'N-9-5' 'S-1']\n",
      "编码后的类别数： 207\n",
      "训练节点数： 62860\n",
      "测试节点数： 15715\n",
      "第一行文本： WM HOUSE, MC HOUSE 展览馆, 交通银行, 良品铺子\n",
      "文本 hidden state shape: torch.Size([768])\n",
      "Epoch 000, Loss: 5.4506\n",
      "Epoch 020, Loss: 5.1236\n",
      "Epoch 040, Loss: 4.9548\n",
      "Epoch 060, Loss: 4.9230\n",
      "Epoch 080, Loss: 4.8745\n",
      "Epoch 100, Loss: 4.7769\n",
      "Epoch 120, Loss: 4.7573\n",
      "Epoch 140, Loss: 4.7173\n",
      "Epoch 160, Loss: 4.6683\n",
      "Epoch 180, Loss: 4.6252\n",
      "Test Accuracy : 0.0791\n",
      "Precision     : 0.0470\n",
      "Recall        : 0.0339\n",
      "F1-score      : 0.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
