{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LR",
   "id": "5984b1fafebe2359"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-18T11:12:19.807822Z",
     "start_time": "2025-05-18T11:12:08.665743Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Image loading and preprocessing\n",
    "# -----------------------------\n",
    "img_data_dir = '../raw'  # Change to your image-dataset folder path\n",
    "\n",
    "image_features = []  # store 1 024-dimensional image features\n",
    "img_labels = []      # store class labels\n",
    "\n",
    "for class_name in os.listdir(img_data_dir):\n",
    "    class_path = os.path.join(img_data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(class_path, filename)).convert('L')\n",
    "                    img = img.resize((32, 32))\n",
    "                    img_array = np.array(img).flatten()\n",
    "                    image_features.append(img_array)\n",
    "                    img_labels.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "image_features = np.array(image_features, dtype=np.float32) / 255.0\n",
    "img_labels = np.array(img_labels)\n",
    "classes = sorted(np.unique(img_labels))\n",
    "num_classes = len(classes)\n",
    "\n",
    "print(f\"Image samples: {image_features.shape[0]}, feature dimension: {image_features.shape[1]}\")\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Build Dataset and DataLoader\n",
    "# -----------------------------\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, features, labels, classes):\n",
    "        self.features = features\n",
    "        self.labels   = labels\n",
    "        self.class2idx = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.class2idx[self.labels[idx]], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_features, img_labels,\n",
    "    test_size=0.1, random_state=42, stratify=img_labels\n",
    ")\n",
    "\n",
    "train_dataset = ImageDataset(X_train, y_train, classes)\n",
    "test_dataset  = ImageDataset(X_test,  y_test,  classes)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader   = DataLoader(test_dataset,  batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}, test samples: {len(test_dataset)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define a simple image-only classifier\n",
    "# -----------------------------\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=1024, hidden_dim=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model  = ImageClassifier(input_dim=1024, hidden_dim=128, num_classes=num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Train the model\n",
    "# -----------------------------\n",
    "criterion   = nn.CrossEntropyLoss()\n",
    "optimizer   = optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_epochs  = 30\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss   = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}/{num_epochs}, Loss: {total_loss/len(train_dataset):.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Evaluate the model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        logits  = model(X_batch)\n",
    "        preds   = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_targets.extend(y_batch.numpy())\n",
    "\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(all_targets, all_preds, target_names=classes))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image samples: 3344, feature dimension: 1024\n",
      "Classes: [np.str_('Eh-1-1'), np.str_('Eh-1-2'), np.str_('Eh-1-3'), np.str_('Eh-1-4'), np.str_('N-1-1'), np.str_('N-1-2'), np.str_('N-1-3'), np.str_('N-1-4'), np.str_('N-1-5')]\n",
      "Training samples: 3009, test samples: 335\n",
      "Epoch 5/30, Loss: 1.8906\n",
      "Epoch 10/30, Loss: 1.8369\n",
      "Epoch 15/30, Loss: 1.7934\n",
      "Epoch 20/30, Loss: 1.7582\n",
      "Epoch 25/30, Loss: 1.7254\n",
      "Epoch 30/30, Loss: 1.6960\n",
      "Test accuracy: 0.3761\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Eh-1-1       0.35      0.19      0.25        37\n",
      "      Eh-1-2       0.33      0.30      0.31        61\n",
      "      Eh-1-3       0.37      0.24      0.29        42\n",
      "      Eh-1-4       0.39      0.43      0.41        49\n",
      "       N-1-1       0.36      0.67      0.47        87\n",
      "       N-1-2       0.65      0.50      0.56        22\n",
      "       N-1-3       0.00      0.00      0.00        13\n",
      "       N-1-4       0.00      0.00      0.00         6\n",
      "       N-1-5       0.50      0.06      0.10        18\n",
      "\n",
      "    accuracy                           0.38       335\n",
      "   macro avg       0.33      0.26      0.27       335\n",
      "weighted avg       0.37      0.38      0.34       335\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GAT",
   "id": "3ee122b7b6d8570c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "# 1. Data loading and preprocessing\n",
    "# Replace data_dir with the path to your extracted dataset folder\n",
    "data_dir = '../raw'\n",
    "\n",
    "X = []  # store image data\n",
    "y = []  # store class labels\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')          # convert to grayscale\n",
    "                    img = img.resize((32, 32))      # resize to 32 × 32\n",
    "                    img_array = np.array(img).flatten()  # flatten to a 1024-dim vector\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X, dtype='float32') / 255.0  # normalize\n",
    "y = np.array(y)\n",
    "print(\"Total images loaded:\", X.shape[0])\n",
    "print(\"Features per sample:\", X.shape[1])\n",
    "print(\"Original class labels:\", np.unique(y))\n",
    "\n",
    "# 2. Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# 3. Build graph structure (KNN)\n",
    "k = 10  # number of neighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "edge_index = []\n",
    "num_nodes = X.shape[0]\n",
    "for i in range(num_nodes):\n",
    "    for j in indices[i]:\n",
    "        if i != j:                       # exclude self-loops (add if needed)\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])    # add reverse edge for an undirected graph\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# 4. Build PyG Data object\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# Stratified 80 %/20 % train/test node split\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx]   = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "print(\"Training nodes:\", int(train_mask.sum()))\n",
    "print(\"Test nodes    :\", int(test_mask.sum()))\n",
    "\n",
    "# 5. Define the GAT model\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels,\n",
    "                 out_channels, heads=8, dropout=0.6):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels,\n",
    "                            heads=heads, dropout=dropout)\n",
    "        # First layer output dim is hidden_channels * heads\n",
    "        self.gat2 = GATConv(hidden_channels * heads, out_channels,\n",
    "                            heads=1, concat=False, dropout=dropout)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAT(in_channels=X.shape[1],\n",
    "            hidden_channels=64,\n",
    "            out_channels=num_classes).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 6. Train the GAT model\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 7. Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    print(f\"Test accuracy: {acc:.4f}\")\n"
   ],
   "id": "735999a793ee20a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GCN",
   "id": "13148feeefcf3ee2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Image loading and preprocessing\n",
    "# Replace data_dir with the path to your extracted dataset\n",
    "data_dir = '../raw'\n",
    "\n",
    "X = []  # store image data\n",
    "y = []  # store class labels\n",
    "\n",
    "# Traverse the dataset folder; each sub-folder represents a class\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')            # convert to grayscale\n",
    "                    img = img.resize((32, 32))        # resize to 32 × 32\n",
    "                    img_array = np.array(img).flatten()  # flatten to 1 024-dim vector\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X, dtype='float32') / 255.0  # normalize\n",
    "y = np.array(y)\n",
    "print(\"Total images loaded:\", X.shape[0])\n",
    "print(\"Feature dimension per sample:\", X.shape[1])\n",
    "print(\"Original class labels:\", np.unique(y))\n",
    "\n",
    "# 2. Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# 3. Build graph structure with KNN\n",
    "k = 10  # number of neighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "_, indices = nbrs.kneighbors(X)\n",
    "\n",
    "edge_index = []\n",
    "num_nodes = X.shape[0]\n",
    "for i in range(num_nodes):\n",
    "    for j in indices[i]:\n",
    "        if i != j:                       # exclude self-loops (add if needed)\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])    # add reverse edge to make an undirected graph\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# 4. Build PyG Data object\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# Stratified 80 %/20 % train/test node split\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx]   = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "print(\"Training nodes:\", int(train_mask.sum()))\n",
    "print(\"Test nodes    :\", int(test_mask.sum()))\n",
    "\n",
    "# 5. Define the GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(in_channels=X.shape[1],\n",
    "            hidden_channels=64,\n",
    "            out_channels=num_classes).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 6. Train the GCN model\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out  = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 7. Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out  = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    print(f\"Test accuracy: {acc:.4f}\")\n"
   ],
   "id": "94b63fa4bdf1344b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "RESNET",
   "id": "dedbe17534e88588"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. Image loading and preprocessing\n",
    "data_dir = '../raw'  # Change to your dataset path; each subfolder corresponds to a class\n",
    "image_size = (32, 32)  # Image size (H, W)\n",
    "\n",
    "X = []  # store image data\n",
    "y = []  # store class labels\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')               # convert to grayscale\n",
    "                    img = img.resize(image_size)         # resize to 32×32\n",
    "                    img_array = np.array(img, dtype=np.float32) / 255.0  # normalize to [0,1]\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X)  # shape: (N, H, W)\n",
    "y = np.array(y)\n",
    "print(\"Total images loaded:\", X.shape[0])\n",
    "print(\"Image size:\", X.shape[1:], \"Original class labels:\", np.unique(y))\n",
    "\n",
    "# 2. Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# 3. Build Dataset and DataLoader\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images  # shape: (N, H, W)\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # convert to [C, H, W]; grayscale so C = 1\n",
    "        image = self.images[idx]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "train_images, test_images = X[train_idx], X[test_idx]\n",
    "train_labels, test_labels = y_encoded[train_idx], y_encoded[test_idx]\n",
    "\n",
    "train_dataset = ImageDataset(train_images, train_labels)\n",
    "test_dataset  = ImageDataset(test_images,  test_labels)\n",
    "\n",
    "batch_size   = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 4. Define the ResNet model\n",
    "# 4.1 BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes, eps=1e-5)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes, eps=1e-5)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes, eps=1e-5)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# 4.2 ResNet backbone\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10, in_channels=1):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        # For small images, use 3×3 conv with stride 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1  = nn.BatchNorm2d(64, eps=1e-5)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # layer1: no downsampling; layer2–4: downsample\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc      = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride):\n",
    "        layers = [block(self.in_planes, planes, stride)]\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        x = self.layer1(x); x = self.layer2(x)\n",
    "        x = self.layer3(x); x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def resnet18(num_classes, in_channels=1):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes, in_channels=in_channels)\n",
    "\n",
    "# Instantiate the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = resnet18(num_classes=num_classes, in_channels=1).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 5. Training and evaluation\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total   = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs        = model(images)\n",
    "        _, predicted   = torch.max(outputs, 1)\n",
    "        total  += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ],
   "id": "4315e4801efe182d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "heterognn+resnet",
   "id": "1748c5e1f9756729"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Image loading and preprocessing\n",
    "# -----------------------------\n",
    "data_dir   = '../raw'          # Path to your image-dataset folder; each sub-folder is a class\n",
    "image_size = (32, 32)          # Image size (H, W)\n",
    "\n",
    "images = []  # store image data (H, W)\n",
    "labels = []  # store class labels\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')                 # grayscale\n",
    "                    img = img.resize(image_size)\n",
    "                    img_array = np.array(img, dtype=np.float32) / 255.0  # normalize to [0, 1]\n",
    "                    images.append(img_array)\n",
    "                    labels.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "images = np.array(images)      # (N, H, W)\n",
    "labels = np.array(labels)\n",
    "print(\"Total images loaded:\", images.shape[0])\n",
    "print(\"Image size:\", images.shape[1:], \"Original class labels:\", np.unique(labels))\n",
    "\n",
    "# Label encoding\n",
    "le         = LabelEncoder()\n",
    "y_encoded  = le.fit_transform(labels)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# Dataset definition\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images   # (N, H, W)\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # convert to [C, H, W]; grayscale so C = 1\n",
    "        img   = np.expand_dims(self.images[idx], axis=0)\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Train / test split\n",
    "indices = np.arange(len(images))\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "train_images, test_images   = images[train_idx], images[test_idx]\n",
    "train_labels, test_labels   = y_encoded[train_idx], y_encoded[test_idx]\n",
    "\n",
    "train_dataset = ImageDataset(train_images, train_labels)\n",
    "test_dataset  = ImageDataset(test_images,  test_labels)\n",
    "\n",
    "batch_size   = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Graph-data encoding (HeteroGNN)\n",
    "# -----------------------------\n",
    "# Example: suppose your heterogeneous-graph data are stored in a dict;\n",
    "# each node type has its own feature matrix.  Adjust to match your data.\n",
    "graph_data = {\n",
    "    'type1': torch.randn(10, 16),   # 10 nodes, 16-dim features\n",
    "    'type2': torch.randn(15, 16)    # 15 nodes, 16-dim features\n",
    "}\n",
    "\n",
    "class HeteroGNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple heterogeneous-graph encoder.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    in_feats : input feature dimension (assumed identical across types)\n",
    "    hidden_feats : hidden dimension\n",
    "    out_feats : dimension of the final graph embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super().__init__()\n",
    "        # For simplicity every node uses the same two-layer MLP\n",
    "        self.fc1 = nn.Linear(in_feats,  hidden_feats)\n",
    "        self.fc2 = nn.Linear(hidden_feats, out_feats)\n",
    "        \n",
    "    def forward(self, graph_dict):\n",
    "        encodings = []\n",
    "        for _, feats in graph_dict.items():          # feats: (N_i, in_feats)\n",
    "            h = F.relu(self.fc1(feats))\n",
    "            h = self.fc2(h)                          # (N_i, out_feats)\n",
    "            encodings.append(h)\n",
    "        all_feats = torch.cat(encodings, dim=0)      # (Σ nodes, out_feats)\n",
    "        return all_feats.mean(dim=0)                 # (out_feats,)\n",
    "\n",
    "heterognn_encoder = HeteroGNNEncoder(in_feats=16, hidden_feats=32, out_feats=768)\n",
    "heterognn_encoder.eval()\n",
    "with torch.no_grad():\n",
    "    graph_hidden_state = heterognn_encoder(graph_data)  # (768,)\n",
    "print(\"Graph-embedding vector shape:\", graph_hidden_state.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. ResNet with graph-plugin fusion\n",
    "# -----------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, 3, stride, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, 3, 1, 1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(planes)\n",
    "        self.down  = None\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.down = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.down is not None:\n",
    "            identity = self.down(x)\n",
    "        out = self.relu(out + identity)\n",
    "        return out\n",
    "\n",
    "class ResNetPlugin(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes, in_channels=1, graph_dim=768):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, 3, 1, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(64)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], 1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], 2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], 2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], 2)\n",
    "        \n",
    "        self.avgpool   = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_plugin = nn.Linear(512 + graph_dim, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride):\n",
    "        layers = [block(self.in_planes, planes, stride)]\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x, graph_vector):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x); x = self.layer2(x)\n",
    "        x = self.layer3(x); x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x).flatten(1)            # (B, 512)\n",
    "        B = x.size(0)\n",
    "        graph_expanded = graph_vector.unsqueeze(0).expand(B, -1)  # (B, graph_dim)\n",
    "        fused = torch.cat([x, graph_expanded], dim=1)\n",
    "        return self.fc_plugin(fused)\n",
    "\n",
    "def resnet18_plugin(num_classes, in_channels=1, graph_dim=768):\n",
    "    return ResNetPlugin(BasicBlock, [2, 2, 2, 2],\n",
    "                        num_classes=num_classes,\n",
    "                        in_channels=in_channels,\n",
    "                        graph_dim=graph_dim)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Training and evaluation\n",
    "# -----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = resnet18_plugin(num_classes=num_classes, in_channels=1, graph_dim=768).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "graph_hidden_state = graph_hidden_state.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, lbls in train_loader:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs, graph_hidden_state)\n",
    "        loss    = criterion(outputs, lbls)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} — Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Evaluation and confusion matrix\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, lbls in test_loader:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        outputs    = model(imgs, graph_hidden_state)\n",
    "        _, preds   = torch.max(outputs, 1)\n",
    "        total  += lbls.size(0)\n",
    "        correct += (preds == lbls).sum().item()\n",
    "        y_true.extend(lbls.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n"
   ],
   "id": "c60515f2f29cad03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
