{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:33:05.965128Z",
     "start_time": "2025-05-21T13:33:05.949497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_dim=768\n",
    "k = 10\n",
    "test_size=0.2\n",
    "lr=0.005\n",
    "hidden_channels=64"
   ],
   "id": "1345eafaa7f34dd3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-21T13:33:21.593770Z",
     "start_time": "2025-05-21T13:33:05.965128Z"
    }
   },
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load & preprocess images and build the graph\n",
    "# -------------------------------\n",
    "data_dir = '../raw'  # Change to your image-dataset folder path\n",
    "\n",
    "X = []  # store image data (each image flattened to a 1024-dimensional vector)\n",
    "y = []  # store class labels\n",
    "\n",
    "# Traverse the dataset folder; each sub-folder represents a class\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')          # convert to grayscale\n",
    "                    img = img.resize((32, 32))      # resize to 32×32\n",
    "                    img_array = np.array(img).flatten()  # flatten to 1024-dim vector\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X, dtype='float32') / 255.0  # normalize\n",
    "y = np.array(y)\n",
    "print(\"Total images read:\", X.shape[0])\n",
    "print(\"Features per sample:\", X.shape[1])\n",
    "print(\"Original class labels:\", np.unique(y))\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# Build a KNN graph\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "_, indices = nbrs.kneighbors(X)\n",
    "edge_index = []\n",
    "num_nodes = X.shape[0]\n",
    "for i in range(num_nodes):\n",
    "    for j in indices[i]:\n",
    "        if i != j:  # exclude self-loops\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])  # bidirectional edges\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Construct the PyG Data object\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# Split nodes into train/test sets\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(indices, test_size=test_size, random_state=42, stratify=y_encoded)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx]   = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "print(\"Number of training nodes:\", int(train_mask.sum()))\n",
    "print(\"Number of test nodes:\", int(test_mask.sum()))\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Text prior: read Excel and obtain the [CLS] vector via BERT\n",
    "# -------------------------------\n",
    "text_data_path = '../Sample Data Texts.xlsx'  # Change to your Excel file path\n",
    "df_text = pd.read_excel(text_data_path)\n",
    "# Use the first row in “List of Store Names” as plugin information (example only)\n",
    "first_text = df_text['List of Store Names'].iloc[0]\n",
    "print(\"First row text:\", first_text)\n",
    "\n",
    "# Use a pre-trained BERT model (bert-base-chinese if the text is Chinese)\n",
    "tokenizer   = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model  = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs  = tokenizer(first_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = bert_model(**inputs)\n",
    "    # Get the [CLS] token hidden state, shape (1, 768)\n",
    "    text_hidden_state = outputs.last_hidden_state[:, 0, :].squeeze(0)  # (768,)\n",
    "print(\"Text hidden state shape:\", text_hidden_state.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Define a GCN model with text plugin\n",
    "# -------------------------------\n",
    "class GCNPlugin(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, text_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # After fusion the dimension is hidden_channels + text_dim\n",
    "        self.classifier = nn.Linear(hidden_channels + text_dim, out_channels)\n",
    "    \n",
    "    def forward(self, data, text_vector):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x shape: (num_nodes, hidden_channels)\n",
    "        num_nodes = x.size(0)\n",
    "        # Expand text_vector (text_dim,) to (num_nodes, text_dim)\n",
    "        text_expanded = text_vector.unsqueeze(0).expand(num_nodes, -1)\n",
    "        # Fuse: concatenate image embeddings and text plugin\n",
    "        fused = torch.cat([x, text_expanded], dim=1)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCNPlugin(in_channels=X.shape[1],\n",
    "                  hidden_channels=hidden_channels,\n",
    "                  out_channels=num_classes,\n",
    "                  text_dim=text_dim).to(device)\n",
    "data = data.to(device)\n",
    "text_hidden_state = text_hidden_state.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Train the model\n",
    "# -------------------------------\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out  = model(data, text_hidden_state)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Evaluate the model\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out  = model(data, text_hidden_state)\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "    # Only consider test nodes\n",
    "    y_true = data.y[data.test_mask].cpu().numpy()\n",
    "    y_pred = pred[data.test_mask].cpu().numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    rec  = recall_score(y_true, y_pred, average='macro')\n",
    "    f1   = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Test Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision     : {prec:.4f}\")\n",
    "    print(f\"Recall        : {rec:.4f}\")\n",
    "    print(f\"F1-score      : {f1:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images read: 3344\n",
      "Features per sample: 1024\n",
      "Original class labels: ['Eh-1-1' 'Eh-1-2' 'Eh-1-3' 'Eh-1-4' 'N-1-1' 'N-1-2' 'N-1-3' 'N-1-4'\n",
      " 'N-1-5']\n",
      "Number of encoded classes: 9\n",
      "Number of training nodes: 2675\n",
      "Number of test nodes: 669\n",
      "First row text: WM HOUSE, MC HOUSE 展览馆, 交通银行, 良品铺子\n",
      "Text hidden state shape: torch.Size([768])\n",
      "Epoch 000, Loss: 2.1915\n",
      "Epoch 020, Loss: 1.9007\n",
      "Epoch 040, Loss: 1.7992\n",
      "Epoch 060, Loss: 1.7512\n",
      "Epoch 080, Loss: 1.6892\n",
      "Epoch 100, Loss: 1.6553\n",
      "Epoch 120, Loss: 1.5843\n",
      "Epoch 140, Loss: 1.5247\n",
      "Epoch 160, Loss: 1.5405\n",
      "Epoch 180, Loss: 1.4312\n",
      "Test Accuracy : 0.4604\n",
      "Precision     : 0.5317\n",
      "Recall        : 0.3447\n",
      "F1-score      : 0.3550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GAT",
   "id": "55aa06fd498c514"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:33:21.600421Z",
     "start_time": "2025-05-21T13:33:21.593770Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d0d3606ac803445e",
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
