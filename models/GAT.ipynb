{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:28:38.591154Z",
     "start_time": "2025-05-21T13:28:38.575157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_dim=768\n",
    "k = 10\n",
    "test_size=0.2\n",
    "lr=0.005\n",
    "hidden_channels=64"
   ],
   "id": "abdde7572f0cefb0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Image loading, preprocessing, and graph construction\n",
    "# ---------------------------\n",
    "data_dir = '../raw'  # Change to your image-dataset folder path\n",
    "\n",
    "X = []  # store image data (each image flattened to a 1024-dimensional vector)\n",
    "y = []  # store class labels\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img = img.convert('L')          # convert to grayscale\n",
    "                    img = img.resize((32, 32))      # resize to 32×32\n",
    "                    img_array = np.array(img).flatten()  # flatten to 1024-dim vector\n",
    "                    X.append(img_array)\n",
    "                    y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "X = np.array(X, dtype='float32') / 255.0  # normalize to [0, 1]\n",
    "y = np.array(y)\n",
    "print(\"Total images loaded:\", X.shape[0])\n",
    "print(\"Features per sample:\", X.shape[1])\n",
    "print(\"Original class labels:\", np.unique(y))\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of encoded classes:\", num_classes)\n",
    "\n",
    "# Build a KNN graph\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X)\n",
    "_, indices = nbrs.kneighbors(X)\n",
    "\n",
    "edge_index = []\n",
    "num_nodes = X.shape[0]\n",
    "for i in range(num_nodes):\n",
    "    for j in indices[i]:\n",
    "        if i != j:                         # exclude self-loops\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])      # bidirectional edges\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Construct a PyG Data object\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "\n",
    "# Stratified train/test node split\n",
    "indices = np.arange(num_nodes)\n",
    "train_idx, test_idx = train_test_split(indices, test_size=test_size, random_state=42, stratify=y_encoded)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "test_mask[test_idx]   = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "print(\"Training nodes:\", int(train_mask.sum()))\n",
    "print(\"Test nodes    :\", int(test_mask.sum()))\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Text prior: load Excel and obtain the [CLS] vector via BERT\n",
    "# ---------------------------\n",
    "text_data_path = '../Sample Data Texts.xlsx'  # Change to your Excel file path\n",
    "df_text = pd.read_excel(text_data_path)\n",
    "# Take the first row of “List of Store Names” as plugin information (example only)\n",
    "first_text = df_text['List of Store Names'].iloc[0]\n",
    "print(\"First row text:\", first_text)\n",
    "\n",
    "# Use a pre-trained BERT model (bert-base-chinese if the text is Chinese)\n",
    "tokenizer  = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs  = tokenizer(first_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = bert_model(**inputs)\n",
    "    # Extract the [CLS] token hidden state, shape (1, 768)\n",
    "    text_hidden_state = outputs.last_hidden_state[:, 0, :].squeeze(0)  # (768,)\n",
    "print(\"Text hidden state shape:\", text_hidden_state.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Define a plugin-based multimodal GAT model\n",
    "# ---------------------------\n",
    "class GATPlugin(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes, text_dim,\n",
    "                 heads=8, dropout=0.6):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels,\n",
    "                            heads=heads, dropout=dropout)\n",
    "        # First layer output dimension = hidden_channels * heads\n",
    "        self.gat2 = GATConv(hidden_channels * heads, hidden_channels,\n",
    "                            heads=1, concat=False, dropout=dropout)\n",
    "        # Fusion dimension: hidden_channels + text_dim\n",
    "        self.classifier = nn.Linear(hidden_channels + text_dim, num_classes)\n",
    "    \n",
    "    def forward(self, data, text_vector):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)            # (num_nodes, hidden_channels)\n",
    "        num_nodes = x.size(0)\n",
    "        text_expanded = text_vector.unsqueeze(0).expand(num_nodes, -1)\n",
    "        fused = torch.cat([x, text_expanded], dim=1)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GATPlugin(in_channels=X.shape[1],\n",
    "                  hidden_channels=hidden_channels,\n",
    "                  num_classes=num_classes,\n",
    "                  text_dim=text_dim).to(device)\n",
    "data = data.to(device)\n",
    "text_hidden_state = text_hidden_state.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Train the model\n",
    "# ---------------------------\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out  = model(data, text_hidden_state)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Evaluate the model\n",
    "# ---------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out  = model(data, text_hidden_state)\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "    # Only consider test nodes\n",
    "    y_true = data.y[data.test_mask].cpu().numpy()\n",
    "    y_pred = pred[data.test_mask].cpu().numpy()\n",
    "\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    rec  = recall_score(y_true, y_pred, average='macro')\n",
    "    f1   = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(f\"Test Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision     : {prec:.4f}\")\n",
    "    print(f\"Recall        : {rec:.4f}\")\n",
    "    print(f\"F1-score      : {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
