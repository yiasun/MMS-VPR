{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:25:01.071073Z",
     "start_time": "2025-05-21T13:25:01.060101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 30\n",
    "lr=0.0001\n",
    "test_size=0.2"
   ],
   "id": "9c01c4dc478c539e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-21T13:22:07.272703Z",
     "start_time": "2025-05-21T13:21:59.804950Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#####################################\n",
    "# 1. Text Prior: Obtain hidden state from first Excel row via BERT\n",
    "#####################################\n",
    "# Please modify text_data_path to your Excel file path\n",
    "text_data_path = '../Sample Data Texts.xlsx'\n",
    "df_text = pd.read_excel(text_data_path)\n",
    "# Assume the Excel file has a 'List of Store Names' column\n",
    "first_text = df_text['List of Store Names'].iloc[0]\n",
    "print(\"First row text:\", first_text)\n",
    "\n",
    "# Use pre-trained BERT model (e.g., bert-base-chinese if the text is Chinese)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "bert_model.eval()  # Freeze BERT parameters\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(first_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = bert_model(**inputs)\n",
    "    # Use the [CLS] token's hidden state as the text representation\n",
    "    text_hidden_state = outputs.last_hidden_state[:, 0, :]  # shape: (1, 768)\n",
    "    text_hidden_state = text_hidden_state.squeeze(0)       # shape: (768,)\n",
    "print(\"Text hidden state shape:\", text_hidden_state.shape)\n",
    "\n",
    "#####################################\n",
    "# 2. Image Data Loading and Preprocessing (LR branch)\n",
    "#####################################\n",
    "# Please modify img_data_dir to your image dataset folder path\n",
    "# Assume each subfolder name is the class label\n",
    "img_data_dir = '../raw'\n",
    "\n",
    "image_features = []  # store image features (1024 dims)\n",
    "img_labels = []      # store class labels\n",
    "\n",
    "for class_name in os.listdir(img_data_dir):\n",
    "    class_path = os.path.join(img_data_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(class_path, filename))\n",
    "                    img = img.convert('L')        # Convert to grayscale\n",
    "                    img = img.resize((32, 32))    # Resize to 32×32\n",
    "                    img_array = np.array(img).flatten()  # Flatten to 1024-dim vector\n",
    "                    image_features.append(img_array)\n",
    "                    img_labels.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {os.path.join(class_path, filename)}:\", e)\n",
    "\n",
    "image_features = np.array(image_features, dtype='float32') / 255.0\n",
    "img_labels = np.array(img_labels)\n",
    "classes = sorted(np.unique(img_labels))\n",
    "print(\"Number of image samples:\", image_features.shape[0])\n",
    "print(\"Image feature dimension:\", image_features.shape[1])\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "#####################################\n",
    "# 3. Construct Dataset and DataLoader\n",
    "#####################################\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, features, labels, classes):\n",
    "        self.features = features  # shape: (N, 1024)\n",
    "        self.labels = labels      # string labels\n",
    "        self.class2idx = {cls: i for i, cls in enumerate(classes)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        y = self.class2idx[self.labels[idx]]\n",
    "        return x, y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_features, img_labels, test_size=test_size,random_state=42, stratify=img_labels\n",
    ")\n",
    "train_dataset = ImageDataset(X_train, y_train, classes)\n",
    "test_dataset = ImageDataset(X_test, y_test, classes)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "print(\"Training samples:\", len(train_dataset), \"Test samples:\", len(test_dataset))\n",
    "\n",
    "#####################################\n",
    "# 4. Define Multimodal Fusion Model (LR hidden state + BERT hidden state)\n",
    "#####################################\n",
    "# Image branch (LR branch): simple MLP mapping 1024-dim image features to 128-dim hidden vector\n",
    "# Text branch: fixed 768-dim BERT hidden state (as class prior)\n",
    "# Fuse and decode to final class\n",
    "class MultiModalFusion(nn.Module):\n",
    "    def __init__(self, image_input_dim=1024, image_hidden_dim=128, text_dim=768, num_classes=len(classes)):\n",
    "        super(MultiModalFusion, self).__init__()\n",
    "        self.image_branch = nn.Sequential(\n",
    "            nn.Linear(image_input_dim, image_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        fusion_dim = image_hidden_dim + text_dim\n",
    "        self.decoder = nn.Linear(fusion_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x, text_vec):\n",
    "        # x: [batch_size, 1024]\n",
    "        # text_vec: [text_dim], fixed here, needs expansion to batch_size\n",
    "        img_hidden = self.image_branch(x)  # [batch_size, image_hidden_dim]\n",
    "        batch_size = x.size(0)\n",
    "        text_expanded = text_vec.unsqueeze(0).expand(batch_size, -1)  # [batch_size, text_dim]\n",
    "        fusion = torch.cat([img_hidden, text_expanded], dim=1)        # [batch_size, fusion_dim]\n",
    "        logits = self.decoder(fusion)                                 # [batch_size, num_classes]\n",
    "        return logits\n",
    "\n",
    "num_classes = len(classes)\n",
    "model = MultiModalFusion(image_input_dim=1024, image_hidden_dim=128, text_dim=768, num_classes=num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "text_hidden_state = text_hidden_state.to(device)\n",
    "\n",
    "#####################################\n",
    "# 5. Train Model\n",
    "#####################################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_x, text_hidden_state)\n",
    "        loss = criterion(logits, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * batch_x.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "#####################################\n",
    "# 6. Model Evaluation\n",
    "#####################################\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        logits = model(batch_x, text_hidden_state)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(batch_y.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "print(\"Test set accuracy:\", acc)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(all_targets, all_preds, target_names=classes))\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row text: WM HOUSE, MC HOUSE 展览馆, 交通银行, 良品铺子\n",
      "Text hidden state shape: torch.Size([768])\n",
      "Number of image samples: 3344\n",
      "Image feature dimension: 1024\n",
      "Classes: [np.str_('Eh-1-1'), np.str_('Eh-1-2'), np.str_('Eh-1-3'), np.str_('Eh-1-4'), np.str_('N-1-1'), np.str_('N-1-2'), np.str_('N-1-3'), np.str_('N-1-4'), np.str_('N-1-5')]\n",
      "Training samples: 1672 Test samples: 1672\n",
      "Epoch 5/30, Loss: 1.8407\n",
      "Epoch 10/30, Loss: 1.7581\n",
      "Epoch 15/30, Loss: 1.6790\n",
      "Epoch 20/30, Loss: 1.6145\n",
      "Epoch 25/30, Loss: 1.5483\n",
      "Epoch 30/30, Loss: 1.4712\n",
      "Test set accuracy: 0.37260765550239233\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Eh-1-1       0.34      0.43      0.38       186\n",
      "      Eh-1-2       0.35      0.44      0.39       303\n",
      "      Eh-1-3       0.79      0.09      0.16       211\n",
      "      Eh-1-4       0.35      0.65      0.46       243\n",
      "       N-1-1       0.59      0.35      0.44       434\n",
      "       N-1-2       0.26      0.46      0.33       110\n",
      "       N-1-3       0.16      0.12      0.14        65\n",
      "       N-1-4       0.00      0.00      0.00        29\n",
      "       N-1-5       0.28      0.25      0.26        91\n",
      "\n",
      "    accuracy                           0.37      1672\n",
      "   macro avg       0.35      0.31      0.28      1672\n",
      "weighted avg       0.44      0.37      0.36      1672\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\17531\\.conda\\envs\\torch_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d7734fce51a7cfb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
